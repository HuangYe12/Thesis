// API callback
random_posts({"version":"1.0","encoding":"UTF-8","feed":{"xmlns":"http://www.w3.org/2005/Atom","xmlns$openSearch":"http://a9.com/-/spec/opensearchrss/1.0/","xmlns$blogger":"http://schemas.google.com/blogger/2008","xmlns$georss":"http://www.georss.org/georss","xmlns$gd":"http://schemas.google.com/g/2005","xmlns$thr":"http://purl.org/syndication/thread/1.0","id":{"$t":"tag:blogger.com,1999:blog-4433261812355873863"},"updated":{"$t":"2016-12-08T22:16:16.614-08:00"},"category":[{"term":"CUDA Programming Concept"},{"term":"CUDA Basics"},{"term":"CUDA Advance"},{"term":"Optimization in CUDA"},{"term":"CUDA programs Level 1.1"},{"term":"Books on CUDA"},{"term":"Images Processing"},{"term":"CUDA programs Level 1.2"},{"term":"CUDA programs Level 2.1"},{"term":"Compilation"},{"term":"Matlab Coding"},{"term":"C program"},{"term":"Debugging"},{"term":"Installation"},{"term":"CUDA Function"},{"term":"Kepler Features"}],"title":{"type":"text","$t":"CUDA Programming"},"subtitle":{"type":"html","$t":"The Complexity of the Problem is the Simplicity of the Solution "},"link":[{"rel":"http://schemas.google.com/g/2005#feed","type":"application/atom+xml","href":"http:\/\/cuda-programming.blogspot.com\/feeds\/posts\/default"},{"rel":"self","type":"application/atom+xml","href":"http:\/\/www.blogger.com\/feeds\/4433261812355873863\/posts\/default?alt=json-in-script\u0026start-index=61\u0026max-results=1"},{"rel":"alternate","type":"text/html","href":"http:\/\/cuda-programming.blogspot.com\/"},{"rel":"hub","href":"http://pubsubhubbub.appspot.com/"},{"rel":"previous","type":"application/atom+xml","href":"http:\/\/www.blogger.com\/feeds\/4433261812355873863\/posts\/default?alt=json-in-script\u0026start-index=60\u0026max-results=1"},{"rel":"next","type":"application/atom+xml","href":"http:\/\/www.blogger.com\/feeds\/4433261812355873863\/posts\/default?alt=json-in-script\u0026start-index=62\u0026max-results=1"}],"author":[{"name":{"$t":"Nitin Gupta"},"email":{"$t":"noreply@blogger.com"},"gd$image":{"rel":"http://schemas.google.com/g/2005#thumbnail","width":"32","height":"32","src":"\/\/lh5.googleusercontent.com\/-y8J34_QMdZA\/AAAAAAAAAAI\/AAAAAAAAACk\/yRljcINNhbw\/s512-c\/photo.jpg"}}],"generator":{"version":"7.00","uri":"http://www.blogger.com","$t":"Blogger"},"openSearch$totalResults":{"$t":"70"},"openSearch$startIndex":{"$t":"61"},"openSearch$itemsPerPage":{"$t":"1"},"entry":[{"id":{"$t":"tag:blogger.com,1999:blog-4433261812355873863.post-4324175901617773012"},"published":{"$t":"2012-12-25T07:13:00.001-08:00"},"updated":{"$t":"2013-01-12T05:23:50.415-08:00"},"category":[{"scheme":"http://www.blogger.com/atom/ns#","term":"CUDA Basics"},{"scheme":"http://www.blogger.com/atom/ns#","term":"CUDA Programming Concept"}],"title":{"type":"text","$t":"What is Kernel in CUDA Programming"},"content":{"type":"html","$t":"\u003Cdiv dir=\"ltr\" style=\"text-align: left;\" trbidi=\"on\"\u003E\u003Cu style=\"background-color: white; color: #666666; font-family: Tahoma, Arial, 'Century gothic', sans-serif; font-size: large; margin: 0px; padding: 0px;\"\u003E\u003Cb style=\"margin: 0px; padding: 0px;\"\u003EBasic of CUDA Programming: Part 5\u003C\/b\u003E\u003C\/u\u003E\u003Cbr \/\u003E\u003Cu style=\"background-color: white; color: #666666; font-family: Tahoma, Arial, 'Century gothic', sans-serif; font-size: large; margin: 0px; padding: 0px;\"\u003E\u003Cb style=\"margin: 0px; padding: 0px;\"\u003E\u003Cbr \/\u003E\u003C\/b\u003E\u003C\/u\u003E\u003Cbr \/\u003E\u003Cspan style=\"font-family: Arial, Helvetica, sans-serif;\"\u003E\u003Cspan style=\"font-size: large;\"\u003E\u003Cb\u003E\u003Cu\u003EKernels\u003C\/u\u003E\u003C\/b\u003E\u003C\/span\u003E\u0026nbsp;\u003C\/span\u003E\u003Cbr \/\u003E\u003Cspan style=\"font-family: Arial, Helvetica, sans-serif;\"\u003E\u003Cbr \/\u003E\u003C\/span\u003E\u003Cspan style=\"font-family: Arial, Helvetica, sans-serif;\"\u003ECUDA C extends C by allowing the programmer to define C functions, called kernels, that, when called, are executed N times in parallel by N different CUDA threads, as opposed to only once like regular C functions.\u003C\/span\u003E\u003Cbr \/\u003E\u003Cspan style=\"font-family: Arial, Helvetica, sans-serif;\"\u003E\u003Cbr \/\u003E\u003C\/span\u003E\u003Cspan style=\"font-family: Arial, Helvetica, sans-serif;\"\u003EA kernel is defined using the \u003Cspan style=\"color: blue;\"\u003E__global__ \u003C\/span\u003Edeclaration specifier and the number of CUDA threads that execute that kernel for a given kernel call is specified using a new\u003Cspan style=\"color: blue;\"\u003E \u0026lt;\u0026lt;\u0026lt;â€¦\u0026gt;\u0026gt;\u0026gt;\u003C\/span\u003E\u003Cspan style=\"color: lime;\"\u003E \u003C\/span\u003Eexecution configuration syntax. Each thread that executes the kernel is given a unique thread ID that is accessible within the kernel through the built-in threadIdx variable.\u003C\/span\u003E\u003Cbr \/\u003E\u003Cbr \/\u003E\u003Cbr \/\u003ESyntax:\u003Cbr \/\u003E\u003Cdiv style=\"text-align: center;\"\u003E\u003Cb style=\"text-indent: 0.5in;\"\u003E\u003Cspan style=\"color: red; font-size: 16.0pt; mso-bidi-font-family: Calibri; mso-bidi-language: HI; mso-bidi-theme-font: minor-latin;\"\u003E\u003Cbr \/\u003E\u003C\/span\u003E\u003C\/b\u003E\u003C\/div\u003E\u003Cdiv style=\"text-align: center;\"\u003E\u003Cb style=\"text-indent: 0.5in;\"\u003E\u003Cspan style=\"color: blue;\"\u003EKernel_Name\u0026lt;\u0026lt;\u0026lt; GridSize, \u0026nbsp;BlockSize,\u0026nbsp; SMEMSize, \u0026nbsp;\u0026nbsp;Stream\u0026nbsp; \u0026gt;\u0026gt;\u0026gt;(arg,..);\u003C\/span\u003E\u003C\/b\u003E\u003C\/div\u003E\u003Cbr \/\u003E\u003Cdiv class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt;\"\u003E\u003Cbr \/\u003E\u003C\/div\u003E\u003Cdiv class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt;\"\u003EWhere: \u003Co:p\u003E\u003C\/o:p\u003E\u003C\/div\u003E\u003Cdiv class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt;\"\u003E\u003Cb\u003ESMEMsize\u0026nbsp; :\u003C\/b\u003E is the size of Shared Memory at Runtime .\u003Co:p\u003E\u003C\/o:p\u003E\u003C\/div\u003E\u003Cdiv class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt;\"\u003E\u003Cb\u003EStream\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp; \u0026nbsp;\u0026nbsp;\u0026nbsp;\u003C\/b\u003E\u003Cb\u003E:\u003C\/b\u003E is a stream on which kernel will execute.\u003Co:p\u003E\u003C\/o:p\u003E\u003C\/div\u003E\u003Cbr \/\u003ESample Example:\u003Cbr \/\u003E\u003Cbr \/\u003E\u003Cbr \/\u003E\u003Cspan style=\"color: blue; font-family: Arial, Helvetica, sans-serif;\"\u003E\/\/ Kernel definition\u003C\/span\u003E\u003Cbr \/\u003E\u003Cb\u003E\u003Cspan style=\"color: blue; font-family: Arial, Helvetica, sans-serif;\"\u003E\u0026nbsp;__global__ void VecAdd(float* A, float* B, float* C)\u0026nbsp;\u003C\/span\u003E\u003C\/b\u003E\u003Cbr \/\u003E\u003Cspan style=\"color: blue; font-family: Arial, Helvetica, sans-serif;\"\u003E{\u003C\/span\u003E\u003Cbr \/\u003E\u003Cspan style=\"color: blue; font-family: Arial, Helvetica, sans-serif;\"\u003E\u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp;int i = threadIdx.x; C[i] = A[i] + B[i];\u0026nbsp;\u003C\/span\u003E\u003Cbr \/\u003E\u003Cspan style=\"color: blue; font-family: Arial, Helvetica, sans-serif;\"\u003E}\u003C\/span\u003E\u003Cbr \/\u003E\u003Cspan style=\"color: blue; font-family: Arial, Helvetica, sans-serif;\"\u003E\u0026nbsp;int main()\u0026nbsp;\u003C\/span\u003E\u003Cbr \/\u003E\u003Cspan style=\"color: blue; font-family: Arial, Helvetica, sans-serif;\"\u003E{ ...\u003C\/span\u003E\u003Cbr \/\u003E\u003Cspan style=\"color: blue; font-family: Arial, Helvetica, sans-serif;\"\u003E\u0026nbsp; \u0026nbsp; \u0026nbsp;\/\/ Kernel invocation with N threads\u0026nbsp;\u003C\/span\u003E\u003Cbr \/\u003E\u003Cspan style=\"color: blue; font-family: Arial, Helvetica, sans-serif;\"\u003E\u0026nbsp; \u0026nbsp; \u0026nbsp;\u003Cb\u003E VecAdd\u0026lt;\u0026lt;\u0026lt;1, N\u0026gt;\u0026gt;\u0026gt;(A, B, C);\u003C\/b\u003E\u003C\/span\u003E\u003Cbr \/\u003E\u003Cspan style=\"color: blue; font-family: Arial, Helvetica, sans-serif;\"\u003E\u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp;...\u0026nbsp;\u003C\/span\u003E\u003Cbr \/\u003E\u003Cspan style=\"color: blue; font-family: Arial, Helvetica, sans-serif;\"\u003E\u003Cbr \/\u003E\u003C\/span\u003E\u003Cspan style=\"color: blue; font-family: Arial, Helvetica, sans-serif;\"\u003E}\u003C\/span\u003E\u003Cbr \/\u003E\u003Cspan style=\"font-family: Arial, Helvetica, sans-serif;\"\u003EHere, each of the N threads that execute VecAdd() performs one pair-wise addition.\u003C\/span\u003E\u003Cbr \/\u003EYou must be\u0026nbsp;wondered,\u0026nbsp;how grid organized in term of \u0026nbsp;block in term of\u0026nbsp;threads; \u003Ca href=\"http:\/\/cuda-programming.blogspot.in\/2012\/12\/thread-hierarchy-in-cuda-programming.html\"\u003ERead this Post\u003C\/a\u003E\u003Cbr \/\u003E\u003Cbr \/\u003E\u003Cbr \/\u003EFeel free to comment...\u003Cbr \/\u003E\u003Cbr \/\u003E\u0026nbsp;References\u003Cbr \/\u003E\u003Ca href=\"http:\/\/cuda-programming.blogspot.in\/2012\/12\/cuda-c-programming-guide.html\" style=\"background-color: white; border: 0px; color: #f43a40; margin: 0px; outline: none; padding: 0px; text-align: justify; text-decoration: initial; vertical-align: baseline;\"\u003E\u003Cspan style=\"font-family: Arial, Helvetica, sans-serif; font-size: x-small;\"\u003ECUDA C Programming Guide\u003C\/span\u003E\u003C\/a\u003E\u003Cbr \/\u003E\u003Ca href=\"http:\/\/docs.nvidia.com\/cuda\/index.html\"\u003E\u003Cspan style=\"font-family: Arial, Helvetica, sans-serif; font-size: x-small;\"\u003E\u003Cspan id=\"goog_76350698\"\u003E\u003C\/span\u003ECUDA; Nvidia\u003C\/span\u003E\u003C\/a\u003E\u003Cspan id=\"goog_76350699\"\u003E\u003C\/span\u003E\u003C\/div\u003E"},"link":[{"rel":"replies","type":"application/atom+xml","href":"http:\/\/cuda-programming.blogspot.com\/feeds\/4324175901617773012\/comments\/default","title":"Post Comments"},{"rel":"replies","type":"text/html","href":"http:\/\/cuda-programming.blogspot.com\/2012\/12\/what-is-kernel-in-cuda-programming.html#comment-form","title":"0 Comments"},{"rel":"edit","type":"application/atom+xml","href":"http:\/\/www.blogger.com\/feeds\/4433261812355873863\/posts\/default\/4324175901617773012"},{"rel":"self","type":"application/atom+xml","href":"http:\/\/www.blogger.com\/feeds\/4433261812355873863\/posts\/default\/4324175901617773012"},{"rel":"alternate","type":"text/html","href":"http:\/\/cuda-programming.blogspot.com\/2012\/12\/what-is-kernel-in-cuda-programming.html","title":"What is Kernel in CUDA Programming"}],"author":[{"name":{"$t":"Nitin Gupta"},"uri":{"$t":"https:\/\/plus.google.com\/118135070601300565447"},"email":{"$t":"noreply@blogger.com"},"gd$image":{"rel":"http://schemas.google.com/g/2005#thumbnail","width":"16","height":"16","src":"http:\/\/img1.blogblog.com\/img\/b16-rounded.gif"}}],"thr$total":{"$t":"0"}}]}});